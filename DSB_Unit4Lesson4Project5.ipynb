{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import state_union, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package state_union to C:\\Users\\Square\n",
      "[nltk_data]     Bear\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1945-Truman.txt',\n",
       " '1946-Truman.txt',\n",
       " '1947-Truman.txt',\n",
       " '1948-Truman.txt',\n",
       " '1949-Truman.txt',\n",
       " '1950-Truman.txt',\n",
       " '1951-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1954-Eisenhower.txt',\n",
       " '1955-Eisenhower.txt',\n",
       " '1956-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1958-Eisenhower.txt',\n",
       " '1959-Eisenhower.txt',\n",
       " '1960-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1962-Kennedy.txt',\n",
       " '1963-Johnson.txt',\n",
       " '1963-Kennedy.txt',\n",
       " '1964-Johnson.txt',\n",
       " '1965-Johnson-1.txt',\n",
       " '1965-Johnson-2.txt',\n",
       " '1966-Johnson.txt',\n",
       " '1967-Johnson.txt',\n",
       " '1968-Johnson.txt',\n",
       " '1969-Johnson.txt',\n",
       " '1970-Nixon.txt',\n",
       " '1971-Nixon.txt',\n",
       " '1972-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1974-Nixon.txt',\n",
       " '1975-Ford.txt',\n",
       " '1976-Ford.txt',\n",
       " '1977-Ford.txt',\n",
       " '1978-Carter.txt',\n",
       " '1979-Carter.txt',\n",
       " '1980-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1982-Reagan.txt',\n",
       " '1983-Reagan.txt',\n",
       " '1984-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1986-Reagan.txt',\n",
       " '1987-Reagan.txt',\n",
       " '1988-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1990-Bush.txt',\n",
       " '1991-Bush-1.txt',\n",
       " '1991-Bush-2.txt',\n",
       " '1992-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1994-Clinton.txt',\n",
       " '1995-Clinton.txt',\n",
       " '1996-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '1998-Clinton.txt',\n",
       " '1999-Clinton.txt',\n",
       " '2000-Clinton.txt',\n",
       " '2001-GWBush-1.txt',\n",
       " '2001-GWBush-2.txt',\n",
       " '2002-GWBush.txt',\n",
       " '2003-GWBush.txt',\n",
       " '2004-GWBush.txt',\n",
       " '2005-GWBush.txt',\n",
       " '2006-GWBush.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Presidential State of the Unions file ids\n",
    "nltk.download('state_union')\n",
    "state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kennedy's famous 1963 SOTU and Carter's 1980 SOTU \n",
    "kennedy = state_union.raw('1963-Kennedy.txt')\n",
    "carter = state_union.raw('1980-Carter.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse using SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "kennedy_doc = nlp(kennedy)\n",
    "carter_doc = nlp(carter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(PRESIDENT, JIMMY, CARTER, 'S, ADDRESS, TO, A,...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(This, last, few, months, has, not, been, an, ...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(As, we, meet, tonight, ,, it, has, never, bee...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(And, tonight, ,, as, throughout, our, own, ge...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(The, 1980, 's, have, been, born, in, turmoil,...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0  (PRESIDENT, JIMMY, CARTER, 'S, ADDRESS, TO, A,...  Carter\n",
       "1  (This, last, few, months, has, not, been, an, ...  Carter\n",
       "2  (As, we, meet, tonight, ,, it, has, never, bee...  Carter\n",
       "3  (And, tonight, ,, as, throughout, our, own, ge...  Carter\n",
       "4  (The, 1980, 's, have, been, born, in, turmoil,...  Carter"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences\n",
    "carter_sents = [[sent, 'Carter'] for sent in carter_doc.sents]\n",
    "kennedy_sents = [[sent, 'Kennedy'] for sent in kennedy_doc.sents]\n",
    "\n",
    "# Combine\n",
    "sentences = pd.DataFrame(carter_sents + kennedy_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT JIMMY CARTER'S ADDRESS TO A JOINT SESSION OF CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "This last few months has not been an easy time for any of us. As we meet tonight, it has never been more clear that the state of our Union\n",
      "\n",
      "Carter speech length: 3881\n",
      "\n",
      " PRESIDENT JOHN F. KENNEDY'S ANNUAL ADDRESS TO A JOINT SESSION OF CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "I congratulate you all - not merely on your electoral victory but on your selected role in history. For you and I are privileged to serve the great Republic\n",
      "\n",
      "Kennedy speech length: 6291\n"
     ]
    }
   ],
   "source": [
    "# Look at excerpts from each \n",
    "print(carter_doc[:50])\n",
    "print('\\nCarter speech length:', len(carter_doc))\n",
    "\n",
    "print('\\n', kennedy_doc[:50])\n",
    "print('\\nKennedy speech length:', len(kennedy_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words function for each text\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "carter_words = bag_of_words(carter_doc)\n",
    "kennedy_words = bag_of_words(kennedy_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(carter_words + kennedy_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words data frame using combined common words and sentences\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Build data frame\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentences in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentences\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sustain</th>\n",
       "      <th>determine</th>\n",
       "      <th>environment</th>\n",
       "      <th>communist</th>\n",
       "      <th>stable</th>\n",
       "      <th>opinion</th>\n",
       "      <th>fiscal</th>\n",
       "      <th>range</th>\n",
       "      <th>factor</th>\n",
       "      <th>Indian</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>private</th>\n",
       "      <th>superpower</th>\n",
       "      <th>limit</th>\n",
       "      <th>common</th>\n",
       "      <th>toil</th>\n",
       "      <th>CONGRESS</th>\n",
       "      <th>greatly</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(PRESIDENT, JIMMY, CARTER, 'S, ADDRESS, TO, A,...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(This, last, few, months, has, not, been, an, ...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(As, we, meet, tonight, ,, it, has, never, bee...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, tonight, ,, as, throughout, our, own, ge...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, 1980, 's, have, been, born, in, turmoil,...</td>\n",
       "      <td>Carter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 830 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sustain determine environment communist stable opinion fiscal range factor  \\\n",
       "0       0         0           0         0      0       0      0     0      0   \n",
       "1       0         0           0         0      0       0      0     0      0   \n",
       "2       0         0           0         0      0       0      0     0      0   \n",
       "3       0         0           0         0      0       0      0     0      0   \n",
       "4       0         0           0         0      0       0      0     0      0   \n",
       "\n",
       "  Indian     ...     young private superpower limit common toil CONGRESS  \\\n",
       "0      0     ...         0       0          0     0      0    0        1   \n",
       "1      0     ...         0       0          0     0      0    0        0   \n",
       "2      0     ...         0       0          0     0      0    0        0   \n",
       "3      0     ...         0       0          0     0      0    0        0   \n",
       "4      0     ...         0       0          0     0      0    0        0   \n",
       "\n",
       "  greatly                                      text_sentence text_source  \n",
       "0       0  (PRESIDENT, JIMMY, CARTER, 'S, ADDRESS, TO, A,...      Carter  \n",
       "1       0  (This, last, few, months, has, not, been, an, ...      Carter  \n",
       "2       0  (As, we, meet, tonight, ,, it, has, never, bee...      Carter  \n",
       "3       0  (And, tonight, ,, as, throughout, our, own, ge...      Carter  \n",
       "4       0  (The, 1980, 's, have, been, born, in, turmoil,...      Carter  \n",
       "\n",
       "[5 rows x 830 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Features\n",
    "# Grab sentence level documents in NLTK\n",
    "kennedy = state_union.sents('1963-Kennedy.txt')\n",
    "carter = state_union.sents('1980-Carter.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of text \n",
    "kennedy_list = [\" \".join(sent) for sent in kennedy]\n",
    "carter_list = [\" \".join(sent) for sent in carter]\n",
    "joined = kennedy_list + carter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=2, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised Learning Models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Specify model inputs for each feature set\n",
    "\n",
    "# BoW\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']\n",
    "\n",
    "# Tfidf\n",
    "X_tfidf = tfidf\n",
    "Y_tfidf = ['Kennedy']*len(kennedy_list) + ['Carter']*len(carter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Logistic Regression Scores:  [0.7625     0.7375     0.72151899 0.73417722 0.65822785]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 0.7227848101265822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tfidf Logistic Regression Scores: [0.69620253 0.74683544 0.72151899 0.65822785 0.58227848]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 0.6810126582278481\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# BoW\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Logistic Regression Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Random Forest Scores:  [0.5375     0.6625     0.67088608 0.65822785 0.59493671]\n",
      "Avg Score: 0.6047784810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tfidf Random Forest Scores: [0.56962025 0.62025316 0.72151899 0.62025316 0.56962025]\n",
      "Avg Score: 0.6278481012658228\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn import ensemble\n",
    "\n",
    "# BoW\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_bow = rfc.fit(X_bow, Y_bow)\n",
    "print('BoW Random Forest Scores: ', cross_val_score(rfc_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_tfidf = rfc.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow Gradient Boosting Scores: [0.6875     0.5875     0.63291139 0.67088608 0.5443038 ]\n",
      "Avg Score: 0.6296202531645569\n",
      "\n",
      "Tfidf Random Forest Scores: [0.64556962 0.6835443  0.60759494 0.65822785 0.55696203]\n",
      "Avg Score: 0.6354430379746835\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "# BoW\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_bow = clf.fit(X_bow, Y_bow)\n",
    "print('Bow Gradient Boosting Scores:', cross_val_score(clf_bow, X_bow,Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_tfidf = clf.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick A Model and Try to Increase Accuracy by 5%\n",
    "#Model: Logistic Regression Using BoW Feature Set\n",
    "# Increase BoW size\n",
    "\n",
    "# Update function to include 1000 most common words\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Get bags \n",
    "carter_words = bag_of_words(carter_doc)\n",
    "kennedy_words = bag_of_words(kennedy_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(carter_words + kennedy_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "big_bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW (big) Logistic Regression Scores:  [0.75       0.7125     0.72151899 0.73417722 0.63291139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Score  0.7102215189873418\n"
     ]
    }
   ],
   "source": [
    "# Make new X and Y inputs\n",
    "X_big_bow = big_bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_big_bow = big_bow['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr = LogisticRegression()\n",
    "lr_big_bow = lr.fit(X_big_bow, Y_big_bow)\n",
    "print('BoW (big) Logistic Regression Scores: ', cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update function, go back to 500 most common words and add in punctuation\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_stop]\n",
    "                   \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "carter_words = bag_of_words(carter_doc)\n",
    "kennedy_words = bag_of_words(kennedy_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(carter_words + kennedy_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate model features\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun model\n",
    "lr = LogisticRegression(\n",
    "    )\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW #3 - Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
